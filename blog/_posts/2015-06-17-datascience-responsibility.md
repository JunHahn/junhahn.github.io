---
title: "Faceless algorithms or responsible data scientists?"
subtitle: "On responsibility of data scientists over the algorithms they create"
layout: post
tags: [data science]
---

With big data comes big responsibility! But can the data scientists step up and take responsibility of the algorithms they have released?


The amount and variety of data-driven applications is increasing rapidly from industrial solutions to practical ones [affecting our daily lives](http://www.theguardian.com/commentisfree/2015/may/29/big-data-purchase-history-charge-you-more-money). Concerns have been raised about [how algorithms rule the world](http://www.theguardian.com/science/2013/jul/01/how-algorithms-rule-world-nsa). However, in this discussion algorithms are often seen as some faceless entities whose responsibility can not be questioned. But every single algorithm is - at least so far - written by a human, often a data scientist. So it’s fair to ask what responsibility of the possible effects of an algorithm does its creator carry?

<center>
<img src="/blog/figs/2015-06-17-datascience-responsibility/ID-100277011.jpg" alt="Branching Out Background Means Data Output And Internet" width="400">

<br>
<em>Image courtesy of Stuart Miles at FreeDigitalPhotos.net</em>
</center>

What makes the case more serious for complicated data-driven algorithms is that they often incorporate inherent uncertainty in their functions and outcomes. This means that it is not always easy or even possible to see beforehand how the algorithms affects the environment they operate in. In addition to some clearly evil applications, such as unwarranted surveillance, there is a huge gray area in where the algorithms have been designed for a good cause, but they may have unforeseen [side effects](http://mathbabe.org/2014/10/20/big-datas-disparate-impact/) that surface only years later.

So what can be done? At least these issues need to be brought to the public discussion. An example of this kind of action is [Data Justice](http://www.datajustice.org), founded in order to “Challenge Rising Exploitation and Economic Inequality from Big Data”. Their blog presents important examples of how data-driven applications may cause unwanted harm. 

Data science curriculum should also involve some [ethics training](http://www.informationweek.com/big-data/big-data-analytics/data-scientists-want-big-data-ethics-standards/d/d-id/1315798). Data scientists should realise that many of the decisions they make when creating data-driven solutions affect other people’s lives, often without them giving consent to it or even even knowing about it. 


In addition, transparency in implementing data science applications would help to increase visibility in the effects of the algorithms. Making the inner workings as transparent as possible might even become a competitive advantage in the future, as people start paying more attention to these issues. The effects of data-driven applications to the end-users could also be part of the usability testing procedure.

Also [algorithmic angels](http://techcrunch.com/2015/04/18/we-need-algorithmic-angels/) 
and other kinds of [watchdogs](http://www.newscientist.com/article/mg22530073.500-living-with-the-algorithms-that-run-our-lives.html) have been proposed to protect us from evil algorithms. Most of all, we need responsible data scientists to realise their powers, actively discuss improvements, and step up for a future where data-driven algorithms remain our tools, not our masters.

